{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import pretty_midi\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi_files(directory):\n",
    "    notes = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mid\"):\n",
    "            midi_data = pretty_midi.PrettyMIDI(os.path.join(directory, filename))\n",
    "            for instrument in midi_data.instruments:\n",
    "                if instrument.is_drum:\n",
    "                    continue\n",
    "                for note in instrument.notes:\n",
    "                    pitch = note.pitch\n",
    "                    duration = note.end - note.start\n",
    "                    notes.append((pitch, duration))\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"./dataset/\"\n",
    "notes = load_midi_files(data_directory)\n",
    "pitchnames = sorted(set(note[0] for note in notes))\n",
    "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "n_vocab = len(pitchnames)\n",
    "network_input = []\n",
    "network_output = []\n",
    "\n",
    "for i in range(len(notes) - sequence_length):\n",
    "    sequence_in = notes[i:i + sequence_length]\n",
    "    sequence_out = notes[i + sequence_length]\n",
    "    network_input.append([note_to_int[note[0]] for note in sequence_in])\n",
    "    network_output.append(note_to_int[sequence_out[0]])\n",
    "\n",
    "n_patterns = len(network_input)\n",
    "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "network_input = network_input / float(n_vocab)\n",
    "network_output = tf.keras.utils.to_categorical(network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(n_vocab, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "62/62 [==============================] - 35s 523ms/step - loss: 3.8769\n",
      "Epoch 2/3\n",
      "62/62 [==============================] - 31s 505ms/step - loss: 3.8551\n",
      "Epoch 3/3\n",
      "62/62 [==============================] - 31s 491ms/step - loss: 3.8508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201d5006470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adamax(learning_rate=0.001))\n",
    "model.fit(network_input, network_output, epochs=3, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='output.mp3'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notes to meaningful music\n",
    "start = np.random.randint(0, len(network_input)-1)\n",
    "pattern = network_input[start]\n",
    "prediction_output = []\n",
    "\n",
    "for _ in range(500):\n",
    "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction_input = prediction_input / float(n_vocab)\n",
    "    prediction = model.predict(prediction_input, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = pitchnames[index]\n",
    "    prediction_output.append(result)\n",
    "    pattern = np.append(pattern, index)\n",
    "    pattern = pattern[1:]\n",
    "\n",
    "midi_stream = pretty_midi.PrettyMIDI()\n",
    "piano_program = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "piano = pretty_midi.Instrument(program=piano_program)\n",
    "\n",
    "for pitch in prediction_output:\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=69, pitch=int(pitch), start=0, end=30\n",
    "    )\n",
    "    piano.notes.append(note)\n",
    "\n",
    "midi_stream.instruments.append(piano)\n",
    "output_path = \"output.mid\"  \n",
    "midi_stream.write(output_path)\n",
    "\n",
    "audio_path = \"output.mp3\"  \n",
    "AudioSegment.from_file(output_path).export(audio_path, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
